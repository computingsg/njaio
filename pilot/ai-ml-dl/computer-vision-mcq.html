<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Computer Vision MCQs - National Junior AI Olympiad</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <style>
        body { font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 0; padding: 20px; background: linear-gradient(135deg, #45b7d1 0%, #2980b9 100%); min-height: 100vh; }
        .container { max-width: 800px; margin: 0 auto; background: white; border-radius: 15px; box-shadow: 0 20px 40px rgba(0,0,0,0.1); overflow: hidden; }
        .header { background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%); color: white; text-align: center; padding: 30px 20px; }
        .header h1 { margin: 0; font-size: 2em; }
        .content { padding: 30px; }
        .back-btn { background: #6c757d; color: white; border: none; padding: 10px 20px; border-radius: 25px; cursor: pointer; text-decoration: none; display: inline-block; margin-bottom: 20px; transition: all 0.3s ease; }
        .back-btn:hover { background: #5a6268; transform: translateY(-2px); }
        .question-container { background: #f8f9fa; border-radius: 12px; padding: 25px; margin-bottom: 25px; border-left: 5px solid #45b7d1; }
        .question-header { display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px; }
        .question-number { font-weight: 600; color: #45b7d1; }
        .question-text { font-size: 1.1em; margin-bottom: 20px; color: #2c3e50; }
        .options { display: grid; gap: 12px; }
        .option { background: white; border: 2px solid #e9ecef; border-radius: 8px; padding: 15px; cursor: pointer; transition: all 0.3s ease; }
        .option:hover { border-color: #45b7d1; background: #e0f7fa; }
        .option.selected.correct { border-color: #4caf50; background: #e8f5e8; }
        .option.selected.incorrect { border-color: #f44336; background: #ffeaea; }
        .explanation { margin-top: 15px; padding: 15px; border-radius: 8px; display: none; }
        .explanation.correct { background: #e8f5e8; border-left: 4px solid #4caf50; color: #2e7d32; }
        .explanation.incorrect { background: #ffeaea; border-left: 4px solid #f44336; color: #c62828; }
        .reset-btn { background: #ff9800; color: white; border: none; padding: 5px 10px; border-radius: 15px; cursor: pointer; font-size: 0.8em; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Computer Vision Practice</h1>
            <p>Test your knowledge of image processing and analysis</p>
        </div>
        <div class="content">
            <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 20px;">
                <a href="computer-vision.html" class="back-btn" style="margin-bottom: 0;"><i class="fas fa-arrow-left"></i> Back to Computer Vision</a>
                <a href="../index.html" class="back-btn" style="background: #2c3e50; margin-bottom: 0;"><i class="fas fa-home"></i> Home</a>
            </div>
            <div id="questions-container"></div>
        </div>
    </div>
    <script>
        const questions = [
            {
                question: "How does a computer 'see' an image?",
                options: ["It interprets the artistic meaning immediately", "It scans the file extension to understand content", "It processes a grid of numbers (pixel values) representing colors/brightness", "It converts the image into audio waves"],
                correct: 2,
                explanation: "Digital images are stored as matrices where each cell contains numerical values (e.g., 0-255) representing the intensity of color channels (Red, Green, Blue). Example: A black-and-white image is just a 2D grid of gray values."
            },
            {
                question: "Why are Convolutional Neural Networks (CNNs) preferred for image tasks over standard dense networks?",
                options: ["They can preserve spatial relationships and detect local features like edges", "They are computationally cheaper for all tasks", "They require significantly less storage space", "They are designed specifically for processing text data"],
                correct: 0,
                explanation: "CNNs use filters (kernels) that slide over the image to detect local patterns (edges, textures) regardless of their position, maintaining the spatial structure. Example: A 'cat ear' detector should work whether the cat is in the top-left or bottom-right corner."
            },
            {
                question: "What is the key difference between Image Classification and Object Detection?",
                options: ["Classification works on grayscale; Detection works on color", "Classification handles video; Detection handles still images", "Detection is a faster version of Classification", "Classification labels the whole image; Detection locates multiple objects"],
                correct: 3,
                explanation: "Classification answers 'What is in this image?' (e.g., 'Dog'). Detection answers 'Where are the objects?' by drawing bounding boxes around them (e.g., 'Dog at [x,y]')."
            },
            {
                question: "What is the purpose of Data Augmentation in Computer Vision?",
                options: ["To increase the resolution of low-quality images", "To compress images to save storage space", "To artificially increase the training dataset size by transforming existing images", "To automatically generate labels for unlabeled data"],
                correct: 2,
                explanation: "Augmentation creates modified versions of training images (rotating, flipping, zooming) to help the model generalize better and avoid overfitting. Example: A rotated cat is still a cat, so training on rotated versions helps the model recognize cats in any orientation."
            },
            {
                question: "How does Transfer Learning benefit Computer Vision tasks?",
                options: ["It speeds up data transfer between servers", "It uses a pre-trained model (e.g., on ImageNet) as a starting point", "It translates text descriptions into images", "It converts color images to grayscale for faster processing"],
                correct: 1,
                explanation: "Instead of training from scratch, you can take a model trained on millions of images (like ResNet) and fine-tune it for your specific small dataset. Example: A model that knows how to recognize 'cars' has already learned to detect edges and wheels, which helps it learn to recognize 'trucks' much faster."
            },
            {
                question: "What are RGB channels in a digital image?",
                options: ["Random, Green, Blue noise patterns", "Red, Gray, Black color spaces", "Red, Green, Blue color components that mix to create all colors", "Real, Generated, Base layers"],
                correct: 2,
                explanation: "Most color images are composed of three channels: Red, Green, and Blue. By mixing different intensities of these three primary colors, millions of distinct colors can be represented."
            },
            {
                question: "What is 'Edge Detection' in image processing?",
                options: ["Identifying the boundaries of objects within an image", "Detecting the physical edges of the monitor", "Cropping the borders of a photograph", "Determining if an image is in focus"],
                correct: 0,
                explanation: "Edge detection algorithms look for sharp changes in brightness or color to identify the outlines and boundaries of objects, which is a fundamental step in understanding the image structure."
            },
            {
                question: "What is the purpose of a 'Pooling Layer' (e.g., Max Pooling) in a CNN?",
                options: ["To increase the color saturation", "To upscale the image resolution", "To reduce the spatial dimensions (downsampling) while keeping important features", "To blend adjacent pixels together"],
                correct: 2,
                explanation: "Pooling layers reduce the spatial dimensions of the data (e.g., taking the maximum value in a 2x2 grid). This reduces the computational load and makes the model more robust to small shifts in the image."
            },
            {
                question: "What is Image Segmentation?",
                options: ["Dividing an image into equal-sized grid blocks", "Classifying each individual pixel as belonging to a specific object or class", "Resizing an image to fit a screen", "Converting a color image to black and white"],
                correct: 1,
                explanation: "Unlike simple object detection which draws a box, segmentation colors in the exact shape of the object. Example: In a self-driving car view, painting the road pixels gray, car pixels blue, and pedestrian pixels red."
            },
            {
                question: "Which of these is an ethical concern related to Facial Recognition technology?",
                options: ["It consumes excessive battery power", "It increases the cost of camera hardware", "It struggles with low-light conditions", "Privacy violation and potential bias against certain demographics"],
                correct: 3,
                explanation: "Facial recognition raises privacy concerns about mass surveillance. Additionally, if trained on unbalanced datasets, it may have higher error rates for certain racial or gender groups, leading to unfair outcomes."
            }
        ];
        
        function renderQuestions() {
            const container = document.getElementById('questions-container');
            container.innerHTML = '';
            questions.forEach((q, index) => {
                const qDiv = document.createElement('div');
                qDiv.className = 'question-container';
                qDiv.innerHTML = `
                    <div class="question-header">
                        <div class="question-number">Question ${index + 1}</div>
                        <button class="reset-btn" onclick="resetQuestion(${index})">Reset</button>
                    </div>
                    <div class="question-text">${q.question}</div>
                    <div class="options">
                        ${q.options.map((opt, i) => `
                            <div class="option" onclick="checkAnswer(${index}, ${i}, this)" data-index="${i}">
                                ${opt}
                            </div>
                        `).join('')}
                    </div>
                    <div class="explanation" id="explanation-${index}"></div>
                `;
                container.appendChild(qDiv);
            });
        }

        function checkAnswer(qIndex, optIndex, element) {
            if (element.classList.contains('selected')) return; 
            
            const question = questions[qIndex];
            const options = element.parentElement.children;
            
            for (let opt of options) {
                opt.classList.add('selected');
                if (opt.dataset.index == question.correct) {
                    opt.classList.add('correct'); 
                }
            }
            
            const explanationDiv = document.getElementById(`explanation-${qIndex}`);
            if (optIndex === question.correct) {
                element.classList.add('correct');
                explanationDiv.className = 'explanation correct';
                explanationDiv.innerHTML = `<strong>✓ Correct!</strong><br>${question.explanation}`;
            } else {
                element.classList.add('incorrect');
                explanationDiv.className = 'explanation incorrect';
                explanationDiv.innerHTML = `<strong>✗ Incorrect.</strong><br>${question.explanation}`;
            }
            explanationDiv.style.display = 'block';
        }

        function resetQuestion(index) {
            const container = document.getElementById('questions-container').children[index];
            const options = container.querySelectorAll('.option');
            options.forEach(opt => {
                opt.className = 'option';
            });
            const explanation = document.getElementById(`explanation-${index}`);
            explanation.style.display = 'none';
        }

        renderQuestions();
    </script>
</body>
</html>